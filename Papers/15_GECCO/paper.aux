\relax 
\citation{Li2009}
\citation{Taylor2009}
\citation{Harrington2013}
\citation{sutton1998introduction}
\citation{sutton1988learning}
\citation{schultz1993responses}
\citation{haber2009reward}
\citation{sutton1998introduction}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {2}Reinforcement Learning}{\thepage }}
\citation{Davidson2006}
\citation{Joachimczak08}
\citation{Doursat09}
\citation{CussatBlanc2012a}
\citation{ziegler2001evolving}
\citation{Nicolau10}
\citation{Joachimczak10}
\citation{CussatBlanc2012b}
\citation{Destexhe2004}
\citation{Marder2012}
\citation{Marder2002}
\citation{Katz1995}
\citation{Zhurov2006}
\citation{Schultz1993}
\citation{Montague1996}
\citation{Fellous1998}
\citation{Marder2012}
\citation{Harrington2013}
\@writefile{toc}{\contentsline {section}{\numberline {3}Gene Regulatory Network}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {4}Neuromodulation}{\thepage }}
\citation{Doya2002}
\citation{Schweighofer2003}
\citation{Doya2008}
\citation{stanley2002evolving}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Regulating parameters}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces At every time step, SARSA updates the GRN inputs. The GRN returns updated learning parameters that will be used by the SARSA algorithm.}}{\thepage }}
\newlabel{fig:GRNSARSA}{{1}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}GRN Optimization}{\thepage }}
\citation{cussatblanc2015grneat}
\citation{Moore1991}
\citation{Sutton1990}
\citation{Handa2007}
\citation{Boyan1995}
\citation{sutton1996generalization}
\citation{sutton1998introduction}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Mountain car }}{\thepage }}
\newlabel{fig:MC:problem}{{2}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Maze }}{\thepage }}
\newlabel{fig:MZ:problem}{{3}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Puddle world }}{\thepage }}
\newlabel{fig:PW:problem}{{4}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Acrobat }}{\thepage }}
\newlabel{fig:ACP:problem}{{5}{\thepage }}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameters used for evolutions}}{\thepage }}
\newlabel{tab:GREAT:params}{{1}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Problems}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Mountain Car}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Maze}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Puddle World}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}Acrobat}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Mountain car: (a) Convergence curve of the genetic algorithm (lower is better); (b) Regulation of the learning parameters of the best GRN obtained; (c) Comparison of the fitnesses per episode (abscissa) obtained by our neuromodulation with a GRN trained on mountain car (green), with a GRN trained on maze (blue) and with parameter-fixed SARSA algorithm (red). Results are averaged on 100 independent runs. Lower is better.}}{\thepage }}
\newlabel{fig:MC:Results}{{6}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Training GRN on one specific problem}{\thepage }}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Fixed learning parameters for the SARSA algorithm obtained by parameter sampling.}}{\thepage }}
\newlabel{tab:SARSAFixedParams}{{2}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Mountain car}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Maze}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Maze: (a) Regulation of the learning parameters of the besst GRN obtained; (b) Comparison of the fitnesses per episode (abscissa) obtained by our neuromodulation with a GRN trained on maze (green) and with parameter-fixed SARSA algorithm (red). Results are averaged on 100 independent runs. Lower is better.}}{\thepage }}
\newlabel{fig:MZ:Results}{{7}{\thepage }}
\citation{sanchez2014gene}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Detailed results of the 100 runs done on the four problems with the best GRN specifically trained on the problem, with the SARSA algorihtm without neuromodulation, with the GRN trained on the maze (noted GRN$_{m}$ in the table), and a generic GRN trained both on the maze and the mountain car problems (noted GRN$_{g}$). Notice that, for the first two problems (mountain car and maze), lower is better and for the two others (puddle world and acrobat), higher is better. Bold values are best per problem and per row and italic ones are second best.}}{\thepage }}
\newlabel{tab:results}{{3}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Puddle world}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Acrobat}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Generalization of the regulation}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Using the GRN trained on the maze}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Puddle world: (b) Comparison of the fitnesses per episode (abscissa) obtained by our neuromodulation with a GRN trained on this problem (green), a GRN trained on maze (blue), a GRN trained on maze and mountain car (gray) and with the parameter-fixed SARSA algorithm (red). Results are averaged on 100 independent runs. Higher is better.}}{\thepage }}
\newlabel{fig:PW:Results}{{8}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Acrobat: (a) Regulation of the learning parameters of the besst GRN obtained; (b)Comparison of the fitnesses per episode (abscissa) obtained by our neuromodulation with a GRN trained on this problem (green) and a GRN trained on maze (blue) and with the parameter-fixed SARSA algorithm (red). Results are averaged on 100 independent runs. Higher is better. }}{\thepage }}
\newlabel{fig:ACP:Results}{{9}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Behavior of the GRN trained on the maze when used to regulate learning parameters on mountain car, puddle world and acrobat.}}{\thepage }}
\newlabel{fig:all:GRNMazeBehavior}{{10}{\thepage }}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Evolving a generic GRN}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Behavior of the GRN trained on the maze and mountain car when used to regulate learning parameters on other problems.}}{\thepage }}
\newlabel{fig:GRNGenericBehavior}{{11}{\thepage }}
\citation{Schweighofer2003}
\citation{Gold2014}
\bibstyle{abbrv}
\bibdata{bibtex}
\bibcite{Boyan1995}{1}
\bibcite{cussatblanc2015grneat}{2}
\bibcite{CussatBlanc2012a}{3}
\bibcite{CussatBlanc2012b}{4}
\bibcite{Davidson2006}{5}
\bibcite{Destexhe2004}{6}
\bibcite{Doursat09}{7}
\bibcite{Doya2002}{8}
\bibcite{Doya2008}{9}
\bibcite{Fellous1998}{10}
\bibcite{Gold2014}{11}
\bibcite{haber2009reward}{12}
\bibcite{Handa2007}{13}
\bibcite{Harrington2013}{14}
\bibcite{Joachimczak08}{15}
\bibcite{Joachimczak10}{16}
\bibcite{Katz1995}{17}
\bibcite{Li2009}{18}
\bibcite{Marder2012}{19}
\bibcite{Marder2002}{20}
\bibcite{Montague1996}{21}
\bibcite{Moore1991}{22}
\bibcite{Nicolau10}{23}
\bibcite{sanchez2014gene}{24}
\bibcite{schultz1993responses}{25}
\bibcite{Schultz1993}{26}
\bibcite{Schweighofer2003}{27}
\@writefile{toc}{\contentsline {section}{\numberline {7}References}{\thepage }}
\bibcite{stanley2002evolving}{28}
\bibcite{Sutton1990}{29}
\bibcite{sutton1988learning}{30}
\bibcite{sutton1996generalization}{31}
\bibcite{sutton1998introduction}{32}
\bibcite{Taylor2009}{33}
\bibcite{Zhurov2006}{34}
\bibcite{ziegler2001evolving}{35}
