\section{Introduction}

Transfer and multi-task learning has recently been receiving attention within the reinforcement and machine learning communities \cite{Li2009,Taylor2009}. The ability to generalize between learnable tasks is a challenging ambition, that is far from fully solved, but is achievable, as evidenced by biological organisms capable of generalizing across multiple tasks. In this work we use an evolutionary algorithm to optimize gene-regulatory networks (GRNs) that dynamically tune the parameters of a reinforcement learning (RL) algorithm. This genetically-regulated neuromodulation (GRNM) extends previous results where we showed that GRNM can enhance the learning of agents beyond the performance of traditional fixed parameter RL \cite{Harrington2013}. We apply GRNM to additional problem classes, and show that GRNs evolved on agents learning a subset of problems can facilitate learning on previously unencountered problems. 

This paper is organized as follows. Firstly, we briefly summarize reinforcement learning and in more specifically the SARSA algorithm used in this study. Then, an introduction to gene regulatory network is given with the details on the computational model we use. Section 4 shows how we use the regulatory network for neuromodulation. Section 5 presents the four problems we use neuromodulation on and the results of GRNs trained specifically on each problem and the capacity of the GRNs to generalize their behavior to unknown problems.
